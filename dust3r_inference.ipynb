{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 전처리\n"
      ],
      "metadata": {
        "id": "kOuJT3kf5VRr"
      },
      "id": "kOuJT3kf5VRr"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdbvifjKVZoI",
        "outputId": "a92508f7-7943-468f-87c4-213d116a65c2"
      },
      "id": "QdbvifjKVZoI",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# root path\n",
        "root_path = '/content/drive/MyDrive/24YAICON'\n",
        "\n",
        "# scene_name\n",
        "scene_name = 'flowers_small'"
      ],
      "metadata": {
        "id": "OZJlMqsNJUEG"
      },
      "id": "OZJlMqsNJUEG",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(root_path)"
      ],
      "metadata": {
        "id": "QkONeC8gV3Pw"
      },
      "id": "QkONeC8gV3Pw",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Git clone\n",
        "* dust3r, 3DGS 클론"
      ],
      "metadata": {
        "id": "CZFVGKknJebX"
      },
      "id": "CZFVGKknJebX"
    },
    {
      "cell_type": "code",
      "source": [
        "# !git clone https://github.com/graphdeco-inria/gaussian-splatting.git --recursive"
      ],
      "metadata": {
        "id": "Z6nNBSQUjsjP"
      },
      "id": "Z6nNBSQUjsjP",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !git clone https://github.com/naver/dust3r --recursive"
      ],
      "metadata": {
        "id": "ss9HvXuqmI_g"
      },
      "id": "ss9HvXuqmI_g",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Error 방지\n",
        "###Colab Error\n",
        "* 아래 코드로 안되면 python 환경변수 변경 필요\n",
        "\n",
        "* 그래도 안되면 아래 참고:\n",
        "https://medium.com/@tempmailwithpassword/how-to-fix-google-colabs-modulenotfounderror-400ba90043e7"
      ],
      "metadata": {
        "id": "JUfePEOgJuO7"
      },
      "id": "JUfePEOgJuO7"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "fff14bf4-cec5-4ddc-8104-5409d475259c",
      "metadata": {
        "id": "fff14bf4-cec5-4ddc-8104-5409d475259c"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(f\"{root_path}/dust3r\")\n",
        "sys.path.append(f\"{root_path}/gaussian-splatting\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sys.path.append(f\"{root_path}/gaussian-splatting/submodules\")"
      ],
      "metadata": {
        "id": "1gt3l-tM_P33"
      },
      "id": "1gt3l-tM_P33",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sys.path"
      ],
      "metadata": {
        "id": "LpHwcn4jmdco",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ed0b0d6-bf1d-4da6-9822-1cf4cdae7ea7"
      },
      "id": "LpHwcn4jmdco",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/24YAICON/dust3r/croco',\n",
              " '/content',\n",
              " '/env/python',\n",
              " '/usr/lib/python310.zip',\n",
              " '/usr/lib/python3.10',\n",
              " '/usr/lib/python3.10/lib-dynload',\n",
              " '',\n",
              " '/usr/local/lib/python3.10/dist-packages',\n",
              " '/usr/lib/python3/dist-packages',\n",
              " '/usr/local/lib/python3.10/dist-packages/setuptools/_vendor',\n",
              " '/content/drive/MyDrive/24YAICON/dust3r',\n",
              " '/content/drive/MyDrive/24YAICON/gaussian-splatting',\n",
              " '/content/drive/MyDrive/24YAICON/gaussian-splatting/submodules',\n",
              " '/content/drive/MyDrive/24YAICON/dust3r',\n",
              " '/content/drive/MyDrive/24YAICON/gaussian-splatting',\n",
              " '/content/drive/MyDrive/24YAICON/gaussian-splatting/submodules']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoding Error\n"
      ],
      "metadata": {
        "id": "durqOELTMqWM"
      },
      "id": "durqOELTMqWM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "* wild-gs 파일 긁어올 때 가끔 인코딩오류 발생 -> 강제로 오버라이드"
      ],
      "metadata": {
        "id": "Y8ecgYFMKJIZ"
      },
      "id": "Y8ecgYFMKJIZ"
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ],
      "metadata": {
        "id": "Afcx1506_BDl"
      },
      "id": "Afcx1506_BDl",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### simple-knn 대체\n"
      ],
      "metadata": {
        "id": "x1GKu2_9Jsma"
      },
      "id": "x1GKu2_9Jsma"
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = os.path.join(root_path, \"gaussian-splatting\", \"scene\", \"gaussian_model.py\")\n",
        "\n",
        "old_import = \"from simple_knn._C import distCUDA2\"\n",
        "\n",
        "new_import = \"\"\"\\nfrom scipy.spatial import KDTree\n",
        "import torch\n",
        "\n",
        "def distCUDA2(points):\n",
        "    points_np = points.detach().cpu().float().numpy()\n",
        "    dists, inds = KDTree(points_np).query(points_np, k=4)\n",
        "    meanDists = (dists[:, 1:] ** 2).mean(1)\n",
        "\n",
        "    return torch.tensor(meanDists, dtype=points.dtype, device=points.device)\n",
        "\"\"\"\n",
        "\n",
        "with open(file_path, 'r') as file:\n",
        "    file_data = file.read()\n",
        "\n",
        "if old_import in file_data:\n",
        "    file_data = file_data.replace(old_import, new_import)\n",
        "\n",
        "    with open(file_path, 'w') as file:\n",
        "        file.write(file_data)\n",
        "\n",
        "    print(f\"'{file_path}' 파일에서 '{old_import}'이(가) 성공적으로 대체되었습니다.\")\n",
        "else:\n",
        "    print(f\"'{file_path}' 파일에서 '{old_import}' 문구를 찾을 수 없습니다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_J7WPAtDJry1",
        "outputId": "3ada25c5-873e-4f12-98ac-98549abf7bc9"
      },
      "id": "_J7WPAtDJry1",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'/content/drive/MyDrive/24YAICON/gaussian-splatting/scene/gaussian_model.py' 파일에서 'from simple_knn._C import distCUDA2' 문구를 찾을 수 없습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation\n",
        "* dust3r ViT모델\n",
        "* requirements.txt"
      ],
      "metadata": {
        "id": "W9iJ_b6o35bx"
      },
      "id": "W9iJ_b6o35bx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### DUSt3R_ViTLarge_BaseDecoder_512"
      ],
      "metadata": {
        "id": "iTFZVL89Ebxh"
      },
      "id": "iTFZVL89Ebxh"
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -nc https://download.europe.naverlabs.com/ComputerVision/DUSt3R/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth -P checkpoints/"
      ],
      "metadata": {
        "id": "1AMeGGsXc9YF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cf916e5-3cfb-4b3d-a72b-1eb525b275cd"
      },
      "id": "1AMeGGsXc9YF",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-10-14 12:48:34--  https://download.europe.naverlabs.com/ComputerVision/DUSt3R/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth\n",
            "Resolving download.europe.naverlabs.com (download.europe.naverlabs.com)... 110.234.56.25\n",
            "Connecting to download.europe.naverlabs.com (download.europe.naverlabs.com)|110.234.56.25|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2285005731 (2.1G)\n",
            "Saving to: ‘checkpoints/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth.2’\n",
            "\n",
            "DUSt3R_ViTLarge_Bas 100%[===================>]   2.13G  32.0MB/s    in 76s     \n",
            "\n",
            "2024-10-14 12:49:50 (28.8 MB/s) - ‘checkpoints/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth.2’ saved [2285005731/2285005731]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### requirements install & upgrade"
      ],
      "metadata": {
        "id": "x5gUXsCNNz5Q"
      },
      "id": "x5gUXsCNNz5Q"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r {root_path}/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5sAouxCZ5Ta",
        "outputId": "8489c692-f274-4ac7-ca52-e172b414c6a6"
      },
      "id": "F5sAouxCZ5Ta",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: einops==0.8.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/24YAICON/requirements.txt (line 1)) (0.8.0)\n",
            "Requirement already satisfied: gradio==5.0.2 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/24YAICON/requirements.txt (line 2)) (5.0.2)\n",
            "Requirement already satisfied: h5py==3.11.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/24YAICON/requirements.txt (line 3)) (3.11.0)\n",
            "Requirement already satisfied: huggingface_hub==0.25.2 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/24YAICON/requirements.txt (line 4)) (0.25.2)\n",
            "Collecting kapture==1.1.10 (from -r /content/drive/MyDrive/24YAICON/requirements.txt (line 5))\n",
            "  Downloading kapture-1.1.10-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting kapture_localization==1.1.10 (from -r /content/drive/MyDrive/24YAICON/requirements.txt (line 6))\n",
            "  Downloading kapture_localization-1.1.10-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: matplotlib==3.7.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/24YAICON/requirements.txt (line 7)) (3.7.1)\n",
            "Collecting numpy==2.1.2 (from -r /content/drive/MyDrive/24YAICON/requirements.txt (line 8))\n",
            "  Downloading numpy-2.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv_contrib_python==4.10.0.84 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/24YAICON/requirements.txt (line 9)) (4.10.0.84)\n",
            "Requirement already satisfied: opencv_python==4.10.0.84 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/24YAICON/requirements.txt (line 10)) (4.10.0.84)\n",
            "Requirement already satisfied: opencv_python_headless==4.10.0.84 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/24YAICON/requirements.txt (line 11)) (4.10.0.84)\n",
            "Requirement already satisfied: packaging==24.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/24YAICON/requirements.txt (line 12)) (24.1)\n",
            "Requirement already satisfied: Pillow==10.4.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/24YAICON/requirements.txt (line 13)) (10.4.0)\n",
            "Collecting pillow_heif==0.18.0 (from -r /content/drive/MyDrive/24YAICON/requirements.txt (line 14))\n",
            "  Downloading pillow_heif-0.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: plyfile==1.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/24YAICON/requirements.txt (line 15)) (1.1)\n",
            "Collecting poselib==2.0.4 (from -r /content/drive/MyDrive/24YAICON/requirements.txt (line 16))\n",
            "  Downloading poselib-2.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (176 bytes)\n",
            "Collecting pycolmap==3.10.0 (from -r /content/drive/MyDrive/24YAICON/requirements.txt (line 17))\n",
            "  Downloading pycolmap-3.10.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
            "Collecting pymeshlab==2023.12.post2 (from -r /content/drive/MyDrive/24YAICON/requirements.txt (line 18))\n",
            "  Downloading pymeshlab-2023.12.post2-cp310-cp310-manylinux_2_31_x86_64.whl.metadata (3.7 kB)\n",
            "Collecting pyrender==0.1.45 (from -r /content/drive/MyDrive/24YAICON/requirements.txt (line 19))\n",
            "  Downloading pyrender-0.1.45-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting quaternion==3.5.2.post4 (from -r /content/drive/MyDrive/24YAICON/requirements.txt (line 20))\n",
            "  Downloading Quaternion-3.5.2.post4-py3-none-any.whl.metadata (759 bytes)\n",
            "Requirement already satisfied: roma==1.5.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/24YAICON/requirements.txt (line 21)) (1.5.0)\n",
            "Requirement already satisfied: scikit_learn==1.5.2 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/24YAICON/requirements.txt (line 22)) (1.5.2)\n",
            "Collecting scipy==1.14.1 (from -r /content/drive/MyDrive/24YAICON/requirements.txt (line 23))\n",
            "  Downloading scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools==75.1.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/24YAICON/requirements.txt (line 24)) (75.1.0)\n",
            "Requirement already satisfied: tensorflow==2.17.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/24YAICON/requirements.txt (line 25)) (2.17.0)\n",
            "Requirement already satisfied: torch==2.4.1+cu121 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/24YAICON/requirements.txt (line 26)) (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision==0.19.1+cu121 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/24YAICON/requirements.txt (line 27)) (0.19.1+cu121)\n",
            "Requirement already satisfied: tqdm==4.66.5 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/24YAICON/requirements.txt (line 28)) (4.66.5)\n",
            "Requirement already satisfied: trimesh==4.4.9 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/24YAICON/requirements.txt (line 29)) (4.4.9)\n",
            "\u001b[31mERROR: Ignored the following versions that require a different python version: 1.6.2 Requires-Python >=3.7,<3.10; 1.6.3 Requires-Python >=3.7,<3.10; 1.7.0 Requires-Python >=3.7,<3.10; 1.7.1 Requires-Python >=3.7,<3.10\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement waymo_open_dataset==1.0.1 (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for waymo_open_dataset==1.0.1\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade setuptools wheel torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDfNzRzU-RMX",
        "outputId": "6c39dcc4-fa11-41e7-aae0-f096fde4ca5f"
      },
      "id": "IDfNzRzU-RMX",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (0.44.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dust3r"
      ],
      "metadata": {
        "id": "5By2CE8dODuW"
      },
      "id": "5By2CE8dODuW"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "5fe15815-ee0a-4e75-a1ed-d58e10e24758",
      "metadata": {
        "id": "5fe15815-ee0a-4e75-a1ed-d58e10e24758"
      },
      "outputs": [],
      "source": [
        "from dust3r.inference import inference\n",
        "from dust3r.model import load_model\n",
        "from dust3r.utils.image import load_images\n",
        "from dust3r.utils.device import to_numpy\n",
        "from dust3r.image_pairs import make_pairs\n",
        "from dust3r.cloud_opt import global_aligner, GlobalAlignerMode\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "try:\n",
        "    import lovely_tensors as lt\n",
        "except:\n",
        "    ! pip install --upgrade lovely-tensors\n",
        "    import lovely_tensors as lt\n",
        "\n",
        "lt.monkey_patch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "93933eb0-8885-4511-a8de-1071bdf2a270",
      "metadata": {
        "id": "93933eb0-8885-4511-a8de-1071bdf2a270"
      },
      "outputs": [],
      "source": [
        "model_path = f\"{root_path}/dust3r/checkpoints/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth\"\n",
        "device = 'cuda:0'\n",
        "batch_size = 1\n",
        "schedule = 'cosine'\n",
        "lr = 0.01\n",
        "niter = 300"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "554b5195-0a67-401a-8817-a0e5b37e11db",
      "metadata": {
        "id": "554b5195-0a67-401a-8817-a0e5b37e11db"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "Path.ls = lambda x: list(x.iterdir())\n",
        "\n",
        "image_dir = Path(f\"{root_path}/data/images/{scene_name}\")\n",
        "\n",
        "image_files = [str(x) for x in image_dir.ls() if x.suffix.lower() in ['.png', '.jpg']]\n",
        "image_files = sorted(image_files, key=lambda x: int(x.split('DSC')[-1].split('.')[0])) # 인덱스 순으로 정렬"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMvvuI0Yd4GF",
        "outputId": "f88ec5fa-8da4-4dbb-89da-77f7b11562e3"
      },
      "id": "kMvvuI0Yd4GF",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/24YAICON/data/images/flowers_small/_DSC9203.JPG',\n",
              " '/content/drive/MyDrive/24YAICON/data/images/flowers_small/_DSC9205.JPG',\n",
              " '/content/drive/MyDrive/24YAICON/data/images/flowers_small/_DSC9208.JPG']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "1bc8d0fd-3aa4-41f2-ba88-3f257173d4f5",
      "metadata": {
        "id": "1bc8d0fd-3aa4-41f2-ba88-3f257173d4f5",
        "outputId": "471a9090-922d-4be8-d6c4-f7a0d65c5c99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "... loading model from /content/drive/MyDrive/24YAICON/dust3r/checkpoints/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/24YAICON/dust3r/dust3r/model.py:30: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(model_path, map_location='cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "instantiating : AsymmetricCroCo3DStereo(enc_depth=24, dec_depth=12, enc_embed_dim=1024, dec_embed_dim=768, enc_num_heads=16, dec_num_heads=12, pos_embed='RoPE100', patch_embed_cls='PatchEmbedDust3R', img_size=(512, 512), head_type='dpt', output_mode='pts3d', depth_mode=('exp', -inf, inf), conf_mode=('exp', 1, inf), landscape_only=False)\n",
            "<All keys matched successfully>\n",
            ">> Loading a list of 3 images\n",
            " - adding /content/drive/MyDrive/24YAICON/data/images/flowers_small/_DSC9203.JPG with resolution 5025x3312 --> 512x336\n",
            " - adding /content/drive/MyDrive/24YAICON/data/images/flowers_small/_DSC9205.JPG with resolution 5025x3312 --> 512x336\n",
            " - adding /content/drive/MyDrive/24YAICON/data/images/flowers_small/_DSC9208.JPG with resolution 5025x3312 --> 512x336\n",
            " (Found 3 images)\n",
            ">> Inference with model on 6 image pairs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/6 [00:00<?, ?it/s]/content/drive/MyDrive/24YAICON/dust3r/dust3r/inference.py:44: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=bool(use_amp)):\n",
            "/content/drive/MyDrive/24YAICON/dust3r/dust3r/model.py:205: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=False):\n",
            "/content/drive/MyDrive/24YAICON/dust3r/dust3r/inference.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=False):\n",
            "100%|██████████| 6/6 [00:05<00:00,  1.06it/s]\n"
          ]
        }
      ],
      "source": [
        "model = load_model(model_path, device)\n",
        "images = load_images(image_files, size=512)\n",
        "pairs = make_pairs(images, scene_graph='complete', prefilter=None, symmetrize=True)\n",
        "output = inference(pairs, model, device, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "6595b9e7-3eb0-4a44-9505-bb97b3bb488c",
      "metadata": {
        "id": "6595b9e7-3eb0-4a44-9505-bb97b3bb488c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ec0e165-94e4-44e2-be44-81717ca08b1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " init edge (0*,1*) score=33.26010513305664\n",
            " init edge (1,2*) score=2.7933757305145264\n",
            " init loss = 0.007108738180249929\n",
            "Global alignement - optimizing for:\n",
            "['pw_poses', 'im_depthmaps', 'im_poses', 'im_focals']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [00:16<00:00, 17.89it/s, lr=1.27413e-06 loss=0.00187832]\n"
          ]
        }
      ],
      "source": [
        "scene = global_aligner(output, device=device, mode=GlobalAlignerMode.PointCloudOptimizer)\n",
        "loss = scene.compute_global_alignment(init=\"mst\", niter=niter, schedule=schedule, lr=lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fa6184d-151c-4b6d-9910-6d497f57d44c",
      "metadata": {
        "id": "9fa6184d-151c-4b6d-9910-6d497f57d44c"
      },
      "source": [
        "# Construct colmap dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "0ec50521-d426-4151-9bd7-c1f72454bfad",
      "metadata": {
        "id": "0ec50521-d426-4151-9bd7-c1f72454bfad"
      },
      "outputs": [],
      "source": [
        "def inv(mat):\n",
        "    \"\"\" Invert a torch or numpy matrix\n",
        "    \"\"\"\n",
        "    if isinstance(mat, torch.Tensor):\n",
        "        return torch.linalg.inv(mat)\n",
        "    if isinstance(mat, np.ndarray):\n",
        "        return np.linalg.inv(mat)\n",
        "    raise ValueError(f'bad matrix type = {type(mat)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "342a4c9c-418b-4070-9a52-5b0f022aab50",
      "metadata": {
        "id": "342a4c9c-418b-4070-9a52-5b0f022aab50"
      },
      "outputs": [],
      "source": [
        "intrinsics = scene.get_intrinsics().detach().cpu().numpy()\n",
        "world2cam = inv(scene.get_im_poses().detach()).cpu().numpy()\n",
        "principal_points = scene.get_principal_points().detach().cpu().numpy()\n",
        "focals = scene.get_focals().detach().cpu().numpy()\n",
        "imgs = np.array(scene.imgs)\n",
        "pts3d = [i.detach() for i in scene.get_pts3d()]\n",
        "depth_maps = [i.detach() for i in scene.get_depthmaps()]\n",
        "\n",
        "min_conf_thr = 20\n",
        "scene.min_conf_thr = float(scene.conf_trf(torch.tensor(min_conf_thr)))\n",
        "masks = to_numpy(scene.get_masks())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49d82908-d722-4bd8-be6e-55a88798481e",
      "metadata": {
        "id": "49d82908-d722-4bd8-be6e-55a88798481e"
      },
      "source": [
        "After convertion such data sctructure should appear\n",
        "\n",
        "```\n",
        "│   │   │   ├── images\n",
        "│   │   │   ├── masks\n",
        "│   │   │   ├── sparse/0\n",
        "|   |   |   |    |------cameras.bin\n",
        "|   |   |   |    |------images.bin\n",
        "|   |   |   |    |------points3D.bin\n",
        "|   |   |   |    |------points3D.ply\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "0d54baea-2a00-4872-a64b-be90872907b4",
      "metadata": {
        "id": "0d54baea-2a00-4872-a64b-be90872907b4"
      },
      "outputs": [],
      "source": [
        "save_dir = Path(f\"{root_path}/data/scenes/{scene_name}\")\n",
        "save_dir.mkdir(exist_ok=True, parents=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "f6beff5a-5b8f-4130-b572-09ba73768f83",
      "metadata": {
        "id": "f6beff5a-5b8f-4130-b572-09ba73768f83"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from typing import NamedTuple, Optional\n",
        "import cv2  # Assuming OpenCV is used for image saving\n",
        "from scene.gaussian_model import BasicPointCloud\n",
        "from PIL import Image\n",
        "from scene.colmap_loader import rotmat2qvec\n",
        "from utils.graphics_utils import focal2fov, fov2focal\n",
        "from scene.dataset_readers import storePly\n",
        "\n",
        "class CameraInfo(NamedTuple):\n",
        "    uid: int\n",
        "    R: np.ndarray\n",
        "    T: np.ndarray\n",
        "    FovY: np.ndarray\n",
        "    FovX: np.ndarray\n",
        "    image: np.ndarray\n",
        "    image_path: str\n",
        "    image_name: str\n",
        "    width: int\n",
        "    height: int\n",
        "    mask: Optional[np.ndarray] = None\n",
        "    mono_depth: Optional[np.ndarray] = None\n",
        "\n",
        "class SceneInfo(NamedTuple):\n",
        "    point_cloud: BasicPointCloud\n",
        "    train_cameras: list\n",
        "    test_cameras: list\n",
        "    nerf_normalization: dict\n",
        "    ply_path: str\n",
        "    render_cameras: Optional[list[CameraInfo]] = None\n",
        "\n",
        "def init_filestructure(save_path):\n",
        "    save_path = Path(save_path)\n",
        "    save_path.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "    images_path = save_path / 'images'\n",
        "    masks_path = save_path / 'masks'\n",
        "    sparse_path = save_path / 'sparse/0'\n",
        "\n",
        "    images_path.mkdir(exist_ok=True, parents=True)\n",
        "    masks_path.mkdir(exist_ok=True, parents=True)\n",
        "    sparse_path.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "    return save_path, images_path, masks_path, sparse_path\n",
        "\n",
        "def save_images_masks(imgs, masks, images_path, masks_path):\n",
        "    # Saving images and optionally masks/depth maps\n",
        "    for i, (image, mask) in enumerate(zip(imgs, masks)):\n",
        "        image_save_path = images_path / f\"{i}.png\"\n",
        "\n",
        "        mask_save_path = masks_path / f\"{i}.png\"\n",
        "        image[~mask] = 1.\n",
        "        rgb_image = cv2.cvtColor(image*255, cv2.COLOR_BGR2RGB)\n",
        "        cv2.imwrite(str(image_save_path), rgb_image)\n",
        "\n",
        "        mask = np.repeat(np.expand_dims(mask, -1), 3, axis=2)*255\n",
        "        Image.fromarray(mask.astype(np.uint8)).save(mask_save_path)\n",
        "\n",
        "\n",
        "def save_cameras(focals, principal_points, sparse_path, imgs_shape):\n",
        "    # Save cameras.txt\n",
        "    cameras_file = sparse_path / 'cameras.txt'\n",
        "    with open(cameras_file, 'w') as cameras_file:\n",
        "        cameras_file.write(\"# Camera list with one line of data per camera:\\n\")\n",
        "        cameras_file.write(\"# CAMERA_ID, MODEL, WIDTH, HEIGHT, PARAMS[]\\n\")\n",
        "        for i, (focal, pp) in enumerate(zip(focals, principal_points)):\n",
        "            cameras_file.write(f\"{i} PINHOLE {imgs_shape[2]} {imgs_shape[1]} {focal[0]} {focal[0]} {pp[0]} {pp[1]}\\n\")\n",
        "\n",
        "def save_imagestxt(world2cam, sparse_path):\n",
        "     # Save images.txt\n",
        "    images_file = sparse_path / 'images.txt'\n",
        "    # Generate images.txt content\n",
        "    with open(images_file, 'w') as images_file:\n",
        "        images_file.write(\"# Image list with two lines of data per image:\\n\")\n",
        "        images_file.write(\"# IMAGE_ID, QW, QX, QY, QZ, TX, TY, TZ, CAMERA_ID, NAME\\n\")\n",
        "        images_file.write(\"# POINTS2D[] as (X, Y, POINT3D_ID)\\n\")\n",
        "        for i in range(world2cam.shape[0]):\n",
        "            # Convert rotation matrix to quaternion\n",
        "            rotation_matrix = world2cam[i, :3, :3]\n",
        "            qw, qx, qy, qz = rotmat2qvec(rotation_matrix)\n",
        "            tx, ty, tz = world2cam[i, :3, 3]\n",
        "            images_file.write(f\"{i} {qw} {qx} {qy} {qz} {tx} {ty} {tz} {i} {i}.png\\n\")\n",
        "            images_file.write(\"\\n\") # Placeholder for points, assuming no points are associated with images here\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def save_pointcloud_with_normals(imgs, pts3d, msk, sparse_path):\n",
        "    pc = get_pc(imgs, pts3d, msk)  # Assuming get_pc is defined elsewhere and returns a trimesh point cloud\n",
        "\n",
        "    # Define a default normal, e.g., [0, 1, 0]\n",
        "    default_normal = [0, 1, 0]\n",
        "\n",
        "    # Prepare vertices, colors, and normals for saving\n",
        "    vertices = pc.vertices\n",
        "    colors = pc.colors\n",
        "    normals = np.tile(default_normal, (vertices.shape[0], 1))\n",
        "\n",
        "    save_path = sparse_path / 'points3D.ply'\n",
        "\n",
        "    # Construct the header of the PLY file\n",
        "    header = \"\"\"ply\n",
        "format ascii 1.0\n",
        "element vertex {}\n",
        "property float x\n",
        "property float y\n",
        "property float z\n",
        "property uchar red\n",
        "property uchar green\n",
        "property uchar blue\n",
        "property float nx\n",
        "property float ny\n",
        "property float nz\n",
        "end_header\n",
        "\"\"\".format(len(vertices))\n",
        "\n",
        "    # Write the PLY file\n",
        "    with open(save_path, 'w') as ply_file:\n",
        "        ply_file.write(header)\n",
        "        for vertex, color, normal in zip(vertices, colors, normals):\n",
        "            ply_file.write('{} {} {} {} {} {} {} {} {}\\n'.format(\n",
        "                vertex[0], vertex[1], vertex[2],\n",
        "                int(color[0]), int(color[1]), int(color[2]),\n",
        "                normal[0], normal[1], normal[2]\n",
        "            ))\n",
        "\n",
        "import trimesh\n",
        "def get_pc(imgs, pts3d, mask):\n",
        "    imgs = to_numpy(imgs)\n",
        "    pts3d = to_numpy(pts3d)\n",
        "    mask = to_numpy(mask)\n",
        "\n",
        "    pts = np.concatenate([p[m] for p, m in zip(pts3d, mask)])\n",
        "    col = np.concatenate([p[m] for p, m in zip(imgs, mask)])\n",
        "\n",
        "    pts = pts.reshape(-1, 3)[::3]\n",
        "    col = col.reshape(-1, 3)[::3]\n",
        "\n",
        "    #mock normals:\n",
        "    normals = np.tile([0, 1, 0], (pts.shape[0], 1))\n",
        "\n",
        "    pct = trimesh.PointCloud(pts, colors=col)\n",
        "    pct.vertices_normal = normals  # Manually add normals to the point cloud\n",
        "\n",
        "    return pct#, pts\n",
        "\n",
        "def save_pointcloud(imgs, pts3d, msk, sparse_path):\n",
        "    save_path = sparse_path / 'points3D.ply'\n",
        "    pc = get_pc(imgs, pts3d, msk)\n",
        "\n",
        "    pc.export(save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "c888ccf6-c8f7-4a15-a129-61be14ce3a4b",
      "metadata": {
        "id": "c888ccf6-c8f7-4a15-a129-61be14ce3a4b"
      },
      "outputs": [],
      "source": [
        "save_path, images_path, masks_path, sparse_path = init_filestructure(save_dir)\n",
        "save_images_masks(imgs, masks, images_path, masks_path)\n",
        "save_cameras(focals, principal_points, sparse_path, imgs_shape=imgs.shape)\n",
        "save_imagestxt(world2cam, sparse_path)\n",
        "# save_pointcloud(imgs, pts3d, masks, sparse_path)\n",
        "save_pointcloud_with_normals(imgs, pts3d, masks, sparse_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version\n",
        "import torch\n",
        "print(torch.version.cuda)"
      ],
      "metadata": {
        "id": "4njx_bSKFvcH",
        "outputId": "f3ebd651-a337-44e8-d7e5-51a42cdbed39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "4njx_bSKFvcH",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n",
            "12.1\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "environment": {
      "kernel": "python3",
      "name": "pytorch-gpu.1-13.m103",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m103"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}